{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab3bc86",
   "metadata": {},
   "source": [
    "# CaLPA Scratch Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5ba04",
   "metadata": {},
   "source": [
    "This is a scratch notebook used to test the code and functionality of the AI California Legislative Policy Analysis (CALPA) system. It is not intended for production use and may contain incomplete or experimental code. The purpose of this notebook is to facilitate the development and testing of the CALPA system, including its data processing, analysis, and visualization components. The notebook may include code snippets, comments, and notes related to the development process. Please refer to the official documentation and user guides for the CALPA system for more information on its usage and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f40d4",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fee68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import json\n",
    "import mimetypes\n",
    "import glob\n",
    "import base64\n",
    "import zipfile\n",
    "import io\n",
    "import dotenv\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3d7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Global Settings:\n",
      "- Name: California Legislative Policy Analysis\n",
      "- Title: AI Legislative Policy Analysis\n",
      "- Version: 1.0\n",
      "- Author: Dr. Kostas Alexandridis, GISP\n",
      "Data Dates\n",
      "- Start Date: 2010-12-02\n",
      "- End Date: 2025-04-18\n",
      "- Periods: 2009-2010, 2011-2012, 2013-2014, 2015-2016, 2017-2018, 2019-2020, 2021-2022, 2023-2024, 2025-2026\n",
      "Directory Global Settings:\n",
      "\n",
      "General:\n",
      "- Project: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\n",
      "- Admin: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\admin\n",
      "- Metadata: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\metadata\n",
      "- Analysis: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\analysis\n",
      "Scripts:\n",
      "- Python Calpa Module: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\calpa\n",
      "- Markdown Scripts: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\markdown\n",
      "- RIS Scripts: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\ris\n",
      "Data:\n",
      "- Main Data: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\data\n",
      "- Documents: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\data\\docs\n",
      "- LegiScan: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\data\\legis\n",
      "- LookUp: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\data\\lookup\n",
      "- Markdown: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\data\\md\n",
      "- RIS: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\data\\bbl\n",
      "Graphics:\n",
      "- Main Graphics: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\graphics\n",
      "- Figures: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\graphics\\figs\n",
      "- Presentations: c:\\Users\\ktale\\OneDrive\\Documents\\GitHub\\CaLPA\\graphics\\visual\n"
     ]
    }
   ],
   "source": [
    "# Load the Calpa module located in the scripts/python/calpa directory\n",
    "from calpa import Calpa, LegiScan\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv(os.path.join(os.getcwd(), '.env'))\n",
    "\n",
    "# Instantiate the LegiScan and Calpa classes\n",
    "calpa = Calpa()\n",
    "legiscan = LegiScan()\n",
    "\n",
    "# Create project metadata for the AI project\n",
    "prjMetadata = calpa.projectMetadata(\"AI\", \"0\")\n",
    "\n",
    "# Create the project directories dictionary\n",
    "prjDirs = calpa.projectDirectories(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd456e2d",
   "metadata": {},
   "source": [
    "## Session List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of sessions from LegiScan\n",
    "sessionList = legiscan.getSessionList()\n",
    "\n",
    "# Convert the sessionList to a pandas DataFrame\n",
    "sessionDf = pd.DataFrame(sessionList)\n",
    "sessionDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f36aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the stored sessions list from JSON dictionary on disk (data/lookup directory)\n",
    "sessionListStored = legiscan.getStoredSessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the sessionList and sessionListStored dictionaries for any changes\n",
    "unmatchedSessions = legiscan.matchHash(sessionList, sessionListStored, \"session_hash\", silent=True)\n",
    "\n",
    "# if the unmatchedSessions is empty, print \"All sessions match\", and delete the unmatchedSessions variable\n",
    "if unmatchedSessions is None:\n",
    "    print(\"All sessions match\")\n",
    "    del unmatchedSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b6cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the sessionList to a JSON file in the data/legiscan/json directory\n",
    "with open(os.path.join(prjDirs[\"pathDataLegis\"], \"json\", \"sessionList.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sessionList, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9807416",
   "metadata": {},
   "source": [
    "## Session People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of session people from LegiScan\n",
    "sessionPeople = {}\n",
    "for key, value in sessionList.items():\n",
    "    sessionId = value[\"session_id\"]\n",
    "    sessionPeople[key] = legiscan.getSessionPeople(sessionId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03248850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the stored session People list from JSON dictionary on disk (data/lookup directory)\n",
    "sessionPeopleStored = legiscan.getStoredPeople()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a704343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the sessionPeople and sessionPeopleStored dictionaries for any changes\n",
    "# Create a dictionary to store unmatched people\n",
    "unmatchedPeople = {}\n",
    "# Iterate through each session and compare the people lists\n",
    "for key, value in sessionPeople.items():\n",
    "    unmatchedPeople[key] = {}\n",
    "    unmatched = legiscan.matchHash(sessionPeople[key][\"people\"], sessionPeopleStored[key][\"people\"], \"person_hash\", silent=True)\n",
    "    # If there are unmatched people, store them in the unmatchedPeople dictionary\n",
    "    unmatchedPeople[key] = unmatched if unmatched is not None else None\n",
    "\n",
    "# if the unmatchedPeople is empty, print \"All people match\", and delete the unmatchedPeople variable\n",
    "if all(not value for value in unmatchedPeople.values()):\n",
    "    print(\"All people match\")\n",
    "    # Delete the unmatchedPeople variable\n",
    "    del unmatchedPeople"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the sessionPeople to a JSON file in the data/legiscan/json directory\n",
    "with open(os.path.join(prjDirs[\"pathDataLegis\"], \"json\", \"sessionPeople.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sessionPeople, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf13d61",
   "metadata": {},
   "source": [
    "## Dataset List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41279af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of datasets from LegiScan for each legislative session\n",
    "datasetList = legiscan.getDatasetList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the stored dataset list from JSON dictionary on disk (data/lookup directory)\n",
    "datasetListStored = legiscan.getStoredDatasetList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb90ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the datasetList and datasetListStored dictionaries for any changes\n",
    "unmatchedDatasets = legiscan.matchHash(datasetList, datasetListStored, \"dataset_hash\", silent=True)\n",
    "\n",
    "# if the unmatchedSessions is empty, print \"All sessions match\", and delete the unmatchedSessions variable\n",
    "if unmatchedDatasets is None:\n",
    "    print(\"All datasets match\")\n",
    "    del unmatchedDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the datasetList to a JSON file in the data/legis/json directory\n",
    "with open(os.path.join(prjDirs[\"pathDataLegis\"], \"json\", \"datasetList.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(datasetList, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df1ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a687e1e4",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d3c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiBills = legiscan.getStoredBills(\"AI\")\n",
    "lcBills = legiscan.getStoredBills(\"LC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3572bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "legiscan.updateStoredBills(\"AI\", \"XX999\", 123555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "legiscan.getStoredBills(\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the aiBills.json file from the data/lookup directory\n",
    "aiBillsJson = os.path.join(prjDirs[\"pathDataLookup\"], \"aiBills.json\")\n",
    "with open(aiBillsJson, \"r\", encoding=\"utf-8\") as f:\n",
    "    aiBills = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the aiBills dictionay to a pandas DataFrame\n",
    "aiBillsDf = pd.DataFrame(aiBills)\n",
    "aiBillsDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754815a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
